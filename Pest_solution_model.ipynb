{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1DQ7-tFtBqkT4gmLcjCCW2LrlUK_jB7Wk",
      "authorship_tag": "ABX9TyOFXhZM9g0GdFiSHm02E1vr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aneeq-shaffy/DL-labsheets/blob/main/Pest_solution_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53d083fb"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8288a58d",
        "outputId": "34f3b866-28ca-4673-dd7c-2e39da06484c"
      },
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"imbikramsaha/paddy-doctor\")\n",
        "print(\"Dataset path:\", path)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'paddy-doctor' dataset.\n",
            "Dataset path: /kaggle/input/paddy-doctor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ee4bb33"
      },
      "source": [
        "dataset_root_path = os.path.join(path, 'paddy-disease-classification')\n",
        "train_csv_path = os.path.join(dataset_root_path, 'train.csv')\n",
        "train_images_path = os.path.join(dataset_root_path, 'train_images')\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57ab336d"
      },
      "source": [
        "full_df = pd.read_csv(train_csv_path)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f96a8081",
        "outputId": "c784646b-6c8d-4bff-96ac-255775d85f56"
      },
      "source": [
        "train_df, val_df = train_test_split(\n",
        "    full_df,\n",
        "    test_size=0.1,\n",
        "    stratify=full_df['label'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(len(train_df), len(val_df))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9366 1041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_counts = train_df['label'].value_counts()\n",
        "label_order = sorted(train_df['label'].unique())\n",
        "\n",
        "counts = torch.tensor(\n",
        "    [label_counts[label] for label in label_order],\n",
        "    dtype=torch.float\n",
        ")\n",
        "\n",
        "class_weights = 1.0 / counts\n",
        "class_weights = class_weights / class_weights.sum()\n"
      ],
      "metadata": {
        "id": "AeW_ox4G2_qh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.RandomVerticalFlip(0.5),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.05),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "rare_class_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(0.7),\n",
        "    transforms.RandomVerticalFlip(0.7),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ColorJitter(0.3,0.3,0.3,0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "tPZ9Ej9UG73-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f260eebe"
      },
      "source": [
        "class PaddyDiseaseDataset(Dataset):\n",
        "    def __init__(self, dataframe, img_dir, transform=None, rare_class_transform=None):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.rare_transform = rare_class_transform\n",
        "\n",
        "        self.labels = sorted(self.df['label'].unique())\n",
        "        self.label_to_idx = {l:i for i,l in enumerate(self.labels)}\n",
        "\n",
        "        self.rare_classes = {\n",
        "            \"bacterial_panicle_blight\",\n",
        "            \"bacterial_leaf_streak\",\n",
        "            \"downy_mildew\"\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = os.path.join(self.img_dir, row.label, row.image_id)\n",
        "        label = self.label_to_idx[row.label]\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if row.label in self.rare_classes and self.rare_transform:\n",
        "            image = self.rare_transform(image)\n",
        "        else:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "360aa4ae"
      },
      "source": [
        "train_dataset = PaddyDiseaseDataset(\n",
        "    train_df, train_images_path, train_transform, rare_class_transform\n",
        ")\n",
        "\n",
        "val_dataset = PaddyDiseaseDataset(\n",
        "    val_df, train_images_path, val_transform\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.efficientnet_b1(\n",
        "    weights=models.EfficientNet_B1_Weights.DEFAULT\n",
        ")\n",
        "\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "in_features = model.classifier[1].in_features\n",
        "model.classifier = nn.Linear(in_features, len(label_order))\n"
      ],
      "metadata": {
        "id": "Oo7XMurL5vtO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1edf94fd"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return running_loss / total, correct / total\n",
        "\n",
        "\n",
        "def validate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return running_loss / total, correct / total\n"
      ],
      "metadata": {
        "id": "paDP1phZUijf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        model, train_loader, optimizer, criterion, device\n",
        "    )\n",
        "\n",
        "    val_loss, val_acc = validate(\n",
        "        model, val_loader, criterion, device\n",
        "    )\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    print(\n",
        "        f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "        f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} \"\n",
        "        f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t9s1C1KUjpu",
        "outputId": "0574864a-9519-49e4-ee31-0ec83ed0ab0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] Train Loss: 1.9109 | Train Acc: 0.3915 Val Loss: 1.7421 | Val Acc: 0.4822\n",
            "Epoch [2/10] Train Loss: 1.6059 | Train Acc: 0.4644 Val Loss: 1.6266 | Val Acc: 0.5168\n",
            "Epoch [3/10] Train Loss: 1.4992 | Train Acc: 0.4963 Val Loss: 1.5388 | Val Acc: 0.5591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze last 2 EfficientNet blocks\n",
        "for name, param in model.named_parameters():\n",
        "    if \"features.6\" in name or \"features.7\" in name:\n",
        "        param.requires_grad = True\n"
      ],
      "metadata": {
        "id": "SQ8OTUNEY02a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.AdamW(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=1e-4,\n",
        "    weight_decay=1e-4\n",
        ")\n"
      ],
      "metadata": {
        "id": "F6XyeH0SY34p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train_one_epoch(\n",
        "        model, train_loader, optimizer, criterion, device\n",
        "    )\n",
        "\n",
        "    val_loss, val_acc = validate(\n",
        "        model, val_loader, criterion, device\n",
        "    )\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    print(\n",
        "        f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "        f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} \"\n",
        "        f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "136kBZXEZSZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"label_to_idx\": train_dataset.label_to_idx\n",
        "}, \"paddy_efficientnet_b1.pth\")\n"
      ],
      "metadata": {
        "id": "i491uWuVd6iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PaddyTestDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.images = sorted(os.listdir(img_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.images[idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        image = self.transform(image)\n",
        "\n",
        "        return image, img_name\n"
      ],
      "metadata": {
        "id": "0S4BpGiOd7se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images_path = os.path.join(dataset_root_path, \"test_images\")\n",
        "\n",
        "test_dataset = PaddyTestDataset(test_images_path, val_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "5PqYJpwTeCjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "predictions = []\n",
        "\n",
        "idx_to_label = {v:k for k,v in train_dataset.label_to_idx.items()}\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, names in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        for name, p in zip(names, preds):\n",
        "            predictions.append((name, idx_to_label[p.item()]))\n"
      ],
      "metadata": {
        "id": "QO99rWi6eFJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = pd.DataFrame(predictions, columns=[\"image_id\", \"label\"])\n",
        "pred_df.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"Saved submission.csv\")\n"
      ],
      "metadata": {
        "id": "MApwMgDReIqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"paddy_efficientnet_b1.pth\", map_location='cpu')\n",
        "print(checkpoint['model_state'].keys())\n"
      ],
      "metadata": {
        "id": "0imbBiXRnOkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "\n",
        "# Load checkpoint\n",
        "checkpoint = torch.load(\"paddy_efficientnet_b1.pth\", map_location='cpu')\n",
        "num_classes = len(checkpoint['label_to_idx'])\n",
        "\n",
        "# Create EfficientNetB1 without pretrained weights\n",
        "model = models.efficientnet_b1(weights=None)\n",
        "\n",
        "# Get the input features for the classifier\n",
        "in_features = model.classifier[1].in_features  # should be 1280\n",
        "\n",
        "# Replace Sequential with plain Linear (matches checkpoint)\n",
        "model.classifier = nn.Linear(in_features, num_classes)\n",
        "\n",
        "# Load weights\n",
        "model.load_state_dict(checkpoint['model_state'])\n",
        "model.eval()\n",
        "\n",
        "print(\"✅ Checkpoint loaded successfully\")\n"
      ],
      "metadata": {
        "id": "Zv2bSc6Gn0Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Trace model for TorchScript\n",
        "dummy_input = torch.randn(1, 3, 224, 224)\n",
        "traced_model = torch.jit.trace(model, dummy_input)\n",
        "traced_model.save(\"paddy_efficientnet_b1.pt\")\n",
        "\n",
        "# Convert TorchScript to ONNX first\n",
        "torch.onnx.export(\n",
        "    model, dummy_input, \"paddy_efficientnet_b1.onnx\",\n",
        "    input_names=['input'], output_names=['output'],\n",
        "    opset_version=18\n",
        ")\n",
        "\n",
        "# Then ONNX → TFLite via onnx-tf or tf2onnx\n",
        "# (I can give a ready-to-use script for that next)\n"
      ],
      "metadata": {
        "id": "1oanX_Ann1is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ai-edge-torch\n"
      ],
      "metadata": {
        "id": "xnPlcC5_uN9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch efficientnet-pytorch\n"
      ],
      "metadata": {
        "id": "PNpL3Ukkuvx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"paddy_efficientnet_b1.pth\")\n",
        "model.load_state_dict(checkpoint['model_state'])\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "SX9GlVq3vTp_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}